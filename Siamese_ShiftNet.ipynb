{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbdfaa79",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b1a13d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\accou\\anaconda3\\envs\\sr3\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# general\n",
    "import time\n",
    "from datetime import datetime\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "from pynvml import *\n",
    "import kornia\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11ba4a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom imports\n",
    "from lanczos import lanczos_2d as lanczos\n",
    "from model.shiftnet_losses import define_loss\n",
    "from utils.helper_functions import get_lr\n",
    "from utils.helper_functions import plot_tensors\n",
    "from utils.helper_functions import plot_tensors_extra_info\n",
    "from utils.helper_functions import minmax_percentile\n",
    "from utils.dataloader_spot import dataset_spot6\n",
    "\n",
    "# Sesure DataLoader\n",
    "from utils.dataloader import Dataset as dataset\n",
    "\n",
    "# model\n",
    "from model.shiftnet import ShiftNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5adb7336",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lanczos.lanczos_2d import lanczos_shift\n",
    "from lanczos.lanczos_2d import lanczos_kernel\n",
    "from lanczos import lanczos_2d as lanczos\n",
    "from model.shiftnet import get_thetas\n",
    "from model.shiftnet import apply_shifts\n",
    "from model.shiftnet import get_shift_loss\n",
    "from model.shiftnet import ShiftNet\n",
    "from model.shiftnet_losses import define_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d860b311",
   "metadata": {},
   "source": [
    "# 0. Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7227c400",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"lr\":0.0001, #0.00001\n",
    "    \"batch_size\":8,\n",
    "    \"epochs\":75,\n",
    "    \"shift_factor\":round((1/300)*10,3), #10 stands for pixels - max shift in factor\n",
    "    \"shiftnet_loss_relative\":False,\n",
    "    \n",
    "    \"data_loader\":{\n",
    "        \"batch_size\":8,\n",
    "        \"num_workers\":4,\n",
    "        \"prefetch_factor\":8,\n",
    "        },\n",
    "    \n",
    "    \"logging\":{\n",
    "        # Logging Settings\n",
    "        \"log_freq\":1, # in it\n",
    "        \"image_freq\":100, # in it\n",
    "        \"wandb_project\":\"Siamese_ShiftNet\",\n",
    "        \"wandb_entity\":\"simon-donike\",\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b74b0cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = dataset_spot6(\"data/train/\")\n",
    "train_loader = DataLoader(dataset_train,\n",
    "                          batch_size=config[\"data_loader\"][\"batch_size\"],\n",
    "                          shuffle=True,pin_memory=True,drop_last=True,\n",
    "                          num_workers=config[\"data_loader\"][\"num_workers\"],\n",
    "                          prefetch_factor=config[\"data_loader\"][\"prefetch_factor\"]) # prefetch 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1115df94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tensor(t,title=\"\"):\n",
    "    t_ = t.clone()\n",
    "    t_ = t_[0].cpu().detach().numpy().transpose(1,2,0)\n",
    "    t_ = minmax_percentile(t_)\n",
    "    plt.imshow(t_)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "def shifter(im,shift_factor=0.05):\n",
    "    affinator = torchvision.transforms.Compose([torchvision.transforms.RandomAffine(degrees=0, translate=(shift_factor,shift_factor), scale=None, shear=None,\n",
    "                                    interpolation=torchvision.transforms.InterpolationMode.NEAREST, fill=0 )]) # center=None\n",
    "    im = affinator(im)\n",
    "    return(im)\n",
    "\n",
    "def plot_siamese_info(hr,sr,hr_small,sr_small,encoded_hr,encoded_sr,new_images,thetas,mode=\"return\"):\n",
    "    \n",
    "    # transform images\n",
    "    hr,sr,encoded_hr,encoded_sr = hr[0].cpu().detach().numpy().transpose(1,2,0),sr[0].cpu().detach().numpy().transpose(1,2,0),encoded_hr[0].cpu().detach().numpy().transpose(1,2,0),encoded_sr[0].cpu().detach().numpy().transpose(1,2,0)\n",
    "    hr,sr,encoded_hr,encoded_sr = minmax_percentile(hr),minmax_percentile(sr),minmax_percentile(encoded_hr),minmax_percentile(encoded_sr)\n",
    "    hr_small,sr_small = hr_small[0][0].cpu().detach().numpy(),sr_small[0][0].cpu().detach().numpy()\n",
    "    hr_small,sr_small = minmax_percentile(hr_small),minmax_percentile(sr_small)\n",
    "    \n",
    "    new_images = new_images[0].cpu().detach().numpy().transpose(1,2,0)\n",
    "    new_images = minmax_percentile(new_images)\n",
    "    # prepare thetas\n",
    "    values = thetas.detach().cpu()[0]\n",
    "    \n",
    "    \n",
    "    # create image\n",
    "    fig, axs = plt.subplots(2, 4,figsize=(20,10),facecolor='white')\n",
    "    # plot images\n",
    "    axs[0,0].imshow(hr)\n",
    "    axs[0,0].set_title(\"HR\")\n",
    "    \n",
    "    axs[1,0].imshow(sr)\n",
    "    axs[1,0].set_title(\"SR\")\n",
    "    \n",
    "    axs[0,1].imshow(encoded_hr)\n",
    "    axs[0,1].set_title(\"Encoded HR\")\n",
    "    \n",
    "    axs[1,1].imshow(encoded_sr)\n",
    "    axs[1,1].set_title(\"Encoded SR\")\n",
    "    \n",
    "    axs[0,2].imshow(hr_small)\n",
    "    axs[0,2].set_title(\"Encoded HR ShiftNet window\")\n",
    "    \n",
    "    axs[1,2].imshow(sr_small)\n",
    "    axs[1,2].set_title(\"Encoded SR ShiftNet window\")\n",
    "    \n",
    "    axs[1,3].imshow(new_images)\n",
    "    axs[1,3].set_title(\"Shifted Image\")\n",
    "    \n",
    "    # draw arrow\n",
    "    axs[0,3].arrow(0,0, -1*values[0],-1*values[1],length_includes_head=True,width=0.2)\n",
    "    axs[0,3].set_ylim(-10, 10) # set limits at 10 so they stay the same\n",
    "    axs[0,3].set_xlim(-10, 10) # set limits at 10 so they stay the same\n",
    "    axs[0,3].set_title(\"Pred. Shifts (px)\\nX:  \"+str(round(float(values[0]),2))+\"\\nY:  \" + str(round(float(-1*values[1]),2)))\n",
    "    axs[0,3].set_xticks([-9,-8,-7,-6,-5,-4,-3,-2,-1,0,1,2,3,4,5,6,7,8,9])\n",
    "    axs[0,3].set_yticks([-9,-8,-7,-6,-5,-4,-3,-2,-1,0,1,2,3,4,5,6,7,8,9])\n",
    "    axs[0,3].grid(alpha=0.4) # draw gridlines \n",
    "    if mode==\"show\":\n",
    "        plt.show()\n",
    "        return(None)\n",
    "    if mode == \"return\":\n",
    "        plt.close()\n",
    "        return(fig)\n",
    "    if mode==\"log\":\n",
    "        # return wandb image dtype\n",
    "        buf = io.BytesIO()\n",
    "        fig.savefig(buf)\n",
    "        buf.seek(0)\n",
    "        im = PIL.Image.open(buf)\n",
    "        image = wandb.Image(im, caption=\"Image\")\n",
    "        wandb.log({\"image\":image})\n",
    "        plt.close()\n",
    "        del buf,im,image\n",
    "        return(None)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16e9d195",
   "metadata": {},
   "outputs": [],
   "source": [
    "class siamese_arm(nn.Module):\n",
    "    ''' ShiftNet, a neural network for sub-pixel registration and interpolation with lanczos kernel. '''\n",
    "    \n",
    "    def __init__(self,in_channel=1):\n",
    "        \n",
    "        super(siamese_arm, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(nn.Conv2d(in_channel, 32, 3, padding=1),nn.BatchNorm2d(32),nn.ReLU()) # nn.BatchNorm2d(128)\n",
    "        self.layer2 = nn.Sequential(nn.Conv2d(32, 64, 3, padding=1),nn.BatchNorm2d(64),nn.ReLU())\n",
    "        self.layer3 = nn.Sequential(nn.Conv2d(64, 64, 3, padding=1),nn.BatchNorm2d(64),nn.ReLU())\n",
    "        self.layer4 = nn.Sequential(nn.Conv2d(64, 32, 3, padding=1),nn.BatchNorm2d(32),nn.ReLU())\n",
    "        self.layer5 = nn.Sequential(nn.Conv2d(32, 1, 3, padding=1),nn.BatchNorm2d(1),nn.ReLU())\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Args:\n",
    "            in: (tensor, BxCxWxH): LR or SR image to be encoded before shift determination\n",
    "            out: (tensor, BxCxWxH): encoded image\n",
    "        '''\n",
    "        \n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        return out \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95fc9ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciate Siamese Models\n",
    "arm_hr = siamese_arm(in_channel=3).to(device).train()\n",
    "arm_sr = siamese_arm(in_channel=3).to(device).train()\n",
    "\n",
    "# Instanciate Shiftnet\n",
    "regis_model = ShiftNet(in_channel=1).to(device).train()\n",
    "shiftnet_loss = define_loss(\"MAE\")\n",
    "\n",
    "# set up optimizer\n",
    "# just add both arms + shiftnet\n",
    "optimizer = torch.optim.Adam(list(arm_hr.parameters()) + list(arm_sr.parameters())+\n",
    "                                list(regis_model.parameters()), lr=config[\"lr\"])  # opt\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3,\n",
    "                                           threshold=0.0001, threshold_mode='rel', cooldown=1, min_lr=0.0000001,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d64c47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8bd16ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msimon-donike\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>E:\\GitHub_extern_PhD\\Siamese_ShiftNet\\wandb\\run-20221222_235345-1cvqp82i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/simon-donike/Siamese_ShiftNet/runs/1cvqp82i\" target=\"_blank\">Siamese_ShiftNet_22-12-2022_23-53-43</a></strong> to <a href=\"https://wandb.ai/simon-donike/Siamese_ShiftNet\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##############################################################################| 1250/1250 [05:48<00:00,  3.58it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:43<00:00,  3.63it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:44<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     9: reducing learning rate of group 0 to 1.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##############################################################################| 1250/1250 [05:46<00:00,  3.61it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:44<00:00,  3.63it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.61it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:44<00:00,  3.63it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:44<00:00,  3.63it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:44<00:00,  3.63it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:46<00:00,  3.61it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:44<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##############################################################################| 1250/1250 [05:44<00:00,  3.63it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:47<00:00,  3.60it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:44<00:00,  3.63it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:44<00:00,  3.63it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-07.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:48<00:00,  3.59it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:48<00:00,  3.58it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:44<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:44<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:44<00:00,  3.63it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:44<00:00,  3.63it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:49<00:00,  3.58it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:44<00:00,  3.63it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:44<00:00,  3.63it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:44<00:00,  3.63it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:44<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:44<00:00,  3.63it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:44<00:00,  3.63it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:44<00:00,  3.63it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:44<00:00,  3.63it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:50<00:00,  3.57it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:44<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:44<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:44<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:44<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:44<00:00,  3.63it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:44<00:00,  3.63it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:44<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:44<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:44<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:51<00:00,  3.56it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.61it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:53<00:00,  3.54it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.61it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>General/train_loss</td><td>█▂▃▃▂▂▂▁▃▂▂▂▂▂▁▂▁▂▂▂▁▁▁▂▂▂▁▃▁▂▂▃▂▂▂▂▂▂▂▂</td></tr><tr><td>ShiftNet/HR_encoded_mean</td><td>█▃▃▃▃▃▂▁▃▂▂▃▂▃▃▄▃▃▃▁▂▂▂▂▂▃▂▄▂▃▃▂▁▄▃▂▃▂▃▄</td></tr><tr><td>ShiftNet/SR_encoded_mean</td><td>▄▂▆▇▁▆▁▅▇▆▂▇▁▇▇▇▁▁▂▁▄▁▆▁▁▇▁█▇▂▂▆▁▂▂▁▇▁▇▂</td></tr><tr><td>ShiftNet/lr</td><td>█████▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>ShiftNet/mae</td><td>█▄▅▅▃▂▃▃▄▂▂▂▂▂▂▄▂▃▂▃▁▁▁▂▁▃▂▄▁▂▃▅▃▂▃▂▂▃▂▂</td></tr><tr><td>ShiftNet/mse</td><td>█▃▄▅▃▁▂▃▃▂▂▂▂▂▁▄▂▃▁▂▁▁▁▂▁▃▂▃▂▂▂▅▂▁▂▂▂▃▂▁</td></tr><tr><td>ShiftNet/psnr_loss</td><td>█▆▆▇▅▃▄▅▆▃▃▃▄▄▃▆▄▅▂▄▁▁▁▄▂▅▄▆▄▃▅▇▄▂▅▄▄▅▃▃</td></tr><tr><td>ShiftNet/ssim_loss</td><td>█▅▆▆▄▂▃▃▆▂▂▂▂▃▂▄▂▄▁▃▁▁▁▃▁▃▃▄▂▂▃▇▃▂▃▂▂▄▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>General/train_loss</td><td>0.01455</td></tr><tr><td>ShiftNet/HR_encoded_mean</td><td>0.07173</td></tr><tr><td>ShiftNet/SR_encoded_mean</td><td>0.06899</td></tr><tr><td>ShiftNet/lr</td><td>0.0</td></tr><tr><td>ShiftNet/mae</td><td>0.00823</td></tr><tr><td>ShiftNet/mse</td><td>0.00022</td></tr><tr><td>ShiftNet/psnr_loss</td><td>-36.56149</td></tr><tr><td>ShiftNet/ssim_loss</td><td>0.04939</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">Siamese_ShiftNet_22-12-2022_23-53-43</strong>: <a href=\"https://wandb.ai/simon-donike/Siamese_ShiftNet/runs/1cvqp82i\" target=\"_blank\">https://wandb.ai/simon-donike/Siamese_ShiftNet/runs/1cvqp82i</a><br/>Synced 6 W&B file(s), 900 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221222_235345-1cvqp82i\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# logging settings\n",
    "run_name = \"Siamese_ShiftNet_\"+str(datetime.now().strftime(\"%d-%m-%Y_%H-%M-%S\"))\n",
    "wandb.init(name=run_name,project=config[\"logging\"][\"wandb_project\"], entity=config[\"logging\"][\"wandb_entity\"],config=config)\n",
    "\n",
    "#iterate over epochs\n",
    "for epoch in range(config[\"epochs\"]):\n",
    "    epoch=epoch+1\n",
    "    \n",
    "    # iterate over datalaoder\n",
    "    it=0\n",
    "    for hr in tqdm(train_loader,ascii=True):\n",
    "        it+=1\n",
    "        hr = hr.to(device) # get HR image\n",
    "        sr = shifter(hr).to(device) # generate shifted image\n",
    "\n",
    "        # encode HR and LR\n",
    "        encoded_hr = arm_hr(hr)\n",
    "        encoded_sr = arm_hr(sr)\n",
    "\n",
    "        # calculate predicted thetas\n",
    "        #sr = encoded_sr\n",
    "        #hr = encoded_hr\n",
    "        thetas, hr_small, sr_small = get_thetas(encoded_hr,encoded_sr,regis_model,n_channels=sr.shape[1])\n",
    "        # perform shift based on calculated thetas\n",
    "        new_images,thetas = apply_shifts(sr,thetas,regis_model,n_channels=3)\n",
    "        # calculate train loss according to defined function\n",
    "        train_loss,hr_loss,new_images_loss = get_shift_loss(new_images,encoded_hr,shiftnet_loss,sr_small,hr_small,\n",
    "                                                            relative_loss=config[\"shiftnet_loss_relative\"])\n",
    "\n",
    "        # train network\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        #break\n",
    "        if it%config[\"logging\"][\"log_freq\"]==0 and it!=0:\n",
    "            # Log Shiftnet\n",
    "            losses_shiftnet = {\n",
    "                \"General/train_loss\":train_loss,\n",
    "                \"ShiftNet/mae\":torch.nn.functional.l1_loss(new_images,hr),\n",
    "                \"ShiftNet/mse\":torch.nn.functional.mse_loss(new_images,hr),\n",
    "                \"ShiftNet/ssim_loss\":kornia.losses.ssim_loss(new_images,hr,window_size=5),\n",
    "                \"ShiftNet/psnr_loss\":kornia.losses.psnr_loss(new_images,hr,max_val=1.0),\n",
    "                \"ShiftNet/lr\":get_lr(optimizer),\n",
    "                \"ShiftNet/SR_encoded_mean\":torch.mean(encoded_sr),\n",
    "                \"ShiftNet/HR_encoded_mean\":torch.mean(encoded_hr)}\n",
    "            # send to WandB\n",
    "            wandb.log(losses_shiftnet)\n",
    "        if it%config[\"logging\"][\"image_freq\"]==0 and it!=0:\n",
    "            plot_siamese_info(hr,sr,hr_small,sr_small,encoded_hr,encoded_sr,new_images,thetas,mode=\"log\")\n",
    "    \n",
    "    # end of epoch steps\n",
    "    scheduler.step(train_loss)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6c161da",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"lr\":0.00001, #0.00001\n",
    "    \"batch_size\":8,\n",
    "    \"epochs\":100,\n",
    "    \"shift_factor\":round((1/300)*10,3), #10 stands for pixels - max shift in factor\n",
    "    \"shiftnet_loss_relative\":False,\n",
    "    \n",
    "    \"data_loader\":{\n",
    "        \"batch_size\":8,\n",
    "        \"num_workers\":4,\n",
    "        \"prefetch_factor\":8,\n",
    "        },\n",
    "    \n",
    "    \"logging\":{\n",
    "        # Logging Settings\n",
    "        \"log_freq\":1, # in it\n",
    "        \"image_freq\":100, # in it\n",
    "        \"wandb_project\":\"Siamese_ShiftNet\",\n",
    "        \"wandb_entity\":\"simon-donike\",\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39cff71c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>E:\\GitHub_extern_PhD\\Siamese_ShiftNet\\wandb\\run-20221223_070557-38espq2q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/simon-donike/Siamese_ShiftNet/runs/38espq2q\" target=\"_blank\">Siamese_ShiftNet_23-12-2022_07-05-57</a></strong> to <a href=\"https://wandb.ai/simon-donike/Siamese_ShiftNet\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:46<00:00,  3.61it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:46<00:00,  3.61it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.61it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:46<00:00,  3.61it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:46<00:00,  3.61it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:46<00:00,  3.61it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:46<00:00,  3.61it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:46<00:00,  3.61it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:46<00:00,  3.61it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:46<00:00,  3.61it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:46<00:00,  3.61it/s]\n",
      "100%|##############################################################################| 1250/1250 [06:10<00:00,  3.37it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:44<00:00,  3.63it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:44<00:00,  3.63it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:46<00:00,  3.61it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:44<00:00,  3.63it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:44<00:00,  3.63it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.61it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:48<00:00,  3.59it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:47<00:00,  3.59it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:53<00:00,  3.53it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:50<00:00,  3.57it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:47<00:00,  3.59it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:55<00:00,  3.52it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:48<00:00,  3.58it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:47<00:00,  3.59it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.61it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:49<00:00,  3.57it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.61it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.61it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:46<00:00,  3.61it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:50<00:00,  3.57it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:46<00:00,  3.61it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:46<00:00,  3.61it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:46<00:00,  3.61it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:46<00:00,  3.61it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:46<00:00,  3.61it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:46<00:00,  3.61it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.62it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:45<00:00,  3.61it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:46<00:00,  3.61it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:52<00:00,  3.54it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:46<00:00,  3.60it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:46<00:00,  3.61it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:46<00:00,  3.61it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:46<00:00,  3.61it/s]\n",
      "100%|##############################################################################| 1250/1250 [05:46<00:00,  3.61it/s]\n",
      " 18%|##############5                                                                | 231/1250 [01:08<05:03,  3.36it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [11], line 41\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m#break\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m it\u001b[38;5;241m%\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogging\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_freq\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m it\u001b[38;5;241m!=\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;66;03m# Log Shiftnet\u001b[39;00m\n\u001b[0;32m     37\u001b[0m     losses_shiftnet \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGeneral/train_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m:train_loss,\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShiftNet/mae\u001b[39m\u001b[38;5;124m\"\u001b[39m:torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39ml1_loss(new_images,hr),\n\u001b[0;32m     40\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShiftNet/mse\u001b[39m\u001b[38;5;124m\"\u001b[39m:torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mmse_loss(new_images,hr),\n\u001b[1;32m---> 41\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShiftNet/ssim_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[43mkornia\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlosses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssim_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[0;32m     42\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShiftNet/psnr_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m:kornia\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mpsnr_loss(new_images,hr,max_val\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m),\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShiftNet/lr\u001b[39m\u001b[38;5;124m\"\u001b[39m:get_lr(optimizer),\n\u001b[0;32m     44\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShiftNet/SR_encoded_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m:torch\u001b[38;5;241m.\u001b[39mmean(encoded_sr),\n\u001b[0;32m     45\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShiftNet/HR_encoded_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m:torch\u001b[38;5;241m.\u001b[39mmean(encoded_hr)}\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;66;03m# send to WandB\u001b[39;00m\n\u001b[0;32m     47\u001b[0m     wandb\u001b[38;5;241m.\u001b[39mlog(losses_shiftnet)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sr3\\lib\\site-packages\\kornia\\losses\\ssim.py:48\u001b[0m, in \u001b[0;36mssim_loss\u001b[1;34m(img1, img2, window_size, max_val, eps, reduction, padding)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Function that computes a loss based on the SSIM measurement.\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03mThe loss, or the Structural dissimilarity (DSSIM) is described as:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;124;03m    >>> loss = ssim_loss(input1, input2, 5)\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# compute the ssim map\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m ssim_map: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# compute and reduce the loss\u001b[39;00m\n\u001b[0;32m     51\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp((\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m ssim_map) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sr3\\lib\\site-packages\\kornia\\metrics\\ssim.py:85\u001b[0m, in \u001b[0;36mssim\u001b[1;34m(img1, img2, window_size, max_val, eps, padding)\u001b[0m\n\u001b[0;32m     82\u001b[0m C2: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0.03\u001b[39m \u001b[38;5;241m*\u001b[39m max_val) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# compute local mean per channel\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m mu1: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[43mfilter2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m mu2: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m filter2d(img2, kernel)\n\u001b[0;32m     88\u001b[0m cropping_shape: List[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sr3\\lib\\site-packages\\kornia\\filters\\filter.py:106\u001b[0m, in \u001b[0;36mfilter2d\u001b[1;34m(input, kernel, border_type, normalized, padding)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# prepare kernel\u001b[39;00m\n\u001b[0;32m    105\u001b[0m b, c, h, w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m--> 106\u001b[0m tmp_kernel: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[43mkernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m normalized:\n\u001b[0;32m    109\u001b[0m     tmp_kernel \u001b[38;5;241m=\u001b[39m normalize_kernel2d(tmp_kernel)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _WandbInit._pause_backend at 0x0000026D4885E430> (for post_run_cell):\n"
     ]
    },
    {
     "ename": "ConnectionResetError",
     "evalue": "[WinError 10054] An existing connection was forcibly closed by the remote host",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\sr3\\lib\\site-packages\\backcall\\backcall.py:104\u001b[0m, in \u001b[0;36mcallback_prototype.<locals>.adapt.<locals>.adapted\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    102\u001b[0m                 kwargs\u001b[38;5;241m.\u001b[39mpop(name)\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[39;00m\n\u001b[1;32m--> 104\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m callback(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sr3\\lib\\site-packages\\wandb\\sdk\\wandb_init.py:394\u001b[0m, in \u001b[0;36m_WandbInit._pause_backend\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    392\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun\u001b[38;5;241m.\u001b[39mlog_code(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    393\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaved code: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, res)\n\u001b[1;32m--> 394\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sr3\\lib\\site-packages\\wandb\\sdk\\interface\\interface.py:636\u001b[0m, in \u001b[0;36mInterfaceBase.publish_pause\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    635\u001b[0m     pause \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mPauseRequest()\n\u001b[1;32m--> 636\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpause\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sr3\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py:308\u001b[0m, in \u001b[0;36mInterfaceShared._publish_pause\u001b[1;34m(self, pause)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m, pause: pb\u001b[38;5;241m.\u001b[39mPauseRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    307\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(pause\u001b[38;5;241m=\u001b[39mpause)\n\u001b[1;32m--> 308\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sr3\\lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py:51\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[1;34m(self, record, local)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_record_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sr3\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:221\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m    219\u001b[0m server_req \u001b[38;5;241m=\u001b[39m spb\u001b[38;5;241m.\u001b[39mServerRequest()\n\u001b[0;32m    220\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[1;32m--> 221\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sr3\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:155\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[1;34m(self, msg)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sr3\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:152\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[1;34m(self, msg)\u001b[0m\n\u001b[0;32m    150\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sr3\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    128\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 130\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mConnectionResetError\u001b[0m: [WinError 10054] An existing connection was forcibly closed by the remote host"
     ]
    }
   ],
   "source": [
    "# logging settings\n",
    "run_name = \"Siamese_ShiftNet_\"+str(datetime.now().strftime(\"%d-%m-%Y_%H-%M-%S\"))\n",
    "wandb.init(name=run_name,project=config[\"logging\"][\"wandb_project\"], entity=config[\"logging\"][\"wandb_entity\"],config=config)\n",
    "\n",
    "#iterate over epochs\n",
    "for epoch in range(config[\"epochs\"]):\n",
    "    epoch=epoch+1\n",
    "    \n",
    "    # iterate over datalaoder\n",
    "    it=0\n",
    "    for hr in tqdm(train_loader,ascii=True):\n",
    "        it+=1\n",
    "        hr = hr.to(device) # get HR image\n",
    "        sr = shifter(hr).to(device) # generate shifted image\n",
    "\n",
    "        # encode HR and LR\n",
    "        encoded_hr = arm_hr(hr)\n",
    "        encoded_sr = arm_hr(sr)\n",
    "\n",
    "        # calculate predicted thetas\n",
    "        #sr = encoded_sr\n",
    "        #hr = encoded_hr\n",
    "        thetas, hr_small, sr_small = get_thetas(encoded_hr,encoded_sr,regis_model,n_channels=sr.shape[1])\n",
    "        # perform shift based on calculated thetas\n",
    "        new_images,thetas = apply_shifts(sr,thetas,regis_model,n_channels=3)\n",
    "        # calculate train loss according to defined function\n",
    "        train_loss,hr_loss,new_images_loss = get_shift_loss(new_images,encoded_hr,shiftnet_loss,sr_small,hr_small,\n",
    "                                                            relative_loss=config[\"shiftnet_loss_relative\"])\n",
    "\n",
    "        # train network\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        #break\n",
    "        if it%config[\"logging\"][\"log_freq\"]==0 and it!=0:\n",
    "            # Log Shiftnet\n",
    "            losses_shiftnet = {\n",
    "                \"General/train_loss\":train_loss,\n",
    "                \"ShiftNet/mae\":torch.nn.functional.l1_loss(new_images,hr),\n",
    "                \"ShiftNet/mse\":torch.nn.functional.mse_loss(new_images,hr),\n",
    "                \"ShiftNet/ssim_loss\":kornia.losses.ssim_loss(new_images,hr,window_size=5),\n",
    "                \"ShiftNet/psnr_loss\":kornia.losses.psnr_loss(new_images,hr,max_val=1.0),\n",
    "                \"ShiftNet/lr\":get_lr(optimizer),\n",
    "                \"ShiftNet/SR_encoded_mean\":torch.mean(encoded_sr),\n",
    "                \"ShiftNet/HR_encoded_mean\":torch.mean(encoded_hr)}\n",
    "            # send to WandB\n",
    "            wandb.log(losses_shiftnet)\n",
    "        if it%config[\"logging\"][\"image_freq\"]==0 and it!=0:\n",
    "            plot_siamese_info(hr,sr,hr_small,sr_small,encoded_hr,encoded_sr,new_images,thetas,mode=\"log\")\n",
    "    \n",
    "    # end of epoch steps\n",
    "    scheduler.step(train_loss)\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
